{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Classifying Problem with Single qubit[Stochastic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.optimize import GradientDescentOptimizer\n",
    "from pennylane import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducing\n",
    "np.random.seed(32)\n",
    "\n",
    "# Making a traing dataset of points inside and outside of a circle\n",
    "def Circle(samples, condition = [[0.0, 0.0], np.sqrt(2 / np.pi)]):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    samples : the number of data points we will make\n",
    "    center : center of the circle    \n",
    "    radius : radius of the circle\n",
    "    condition : conditions of the circle (condition[0] = center, condition[1] = radius)\n",
    "    \n",
    "    OUTPUT\n",
    "    data points & labels(In - 0/Out - 1) for each point & Condition\n",
    "    \"\"\"\n",
    "    points= []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        \n",
    "        # Mading sample points\n",
    "        point = 2*np.random.rand(2)-1\n",
    "        label = 0\n",
    "\n",
    "        # Changing label to 1 if it is out of the circle\n",
    "        if np.linalg.norm(point - condition[0]) > condition[1]:\n",
    "            label = 1\n",
    "        \n",
    "        # Collecting the sample points\n",
    "        points.append(point)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(points, requires_grad = False), np.array(labels, requires_grad = False), condition\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "def Sin(samples, condition = [1]):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    samples : the number of data points we will generate\n",
    "    condition : condtion of the sin function (condition[0] = amplitude, condition[1] = frequency)\n",
    "\n",
    "    OUTPUT\n",
    "    data points & labels(Under - 0/Over - 1) for each point & Condition\n",
    "    \"\"\"\n",
    "\n",
    "    points = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        point = 2*np.random.rand(2)-1\n",
    "        label = 0\n",
    "\n",
    "        if point[1] > condition[0]*np.sin(np.pi*point[0]):\n",
    "            label = 1\n",
    "\n",
    "        points.append(point)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(points, requires_grad = False), np.array(labels, requires_grad = False), condition\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "def Square(samples, condition = [[0,0], 3/4]):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    samples : the number of data points we will generate\n",
    "    condtion : codition of the square (condition[0] = center of the square, condtion[1] = side length for the square)\n",
    "\n",
    "    OUTPUT\n",
    "    data points & labels(In - 1/Out - -1) for each point & Condition\n",
    "    \"\"\"\n",
    "    points= []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(samples):\n",
    "        \n",
    "        # Mading sample points\n",
    "        point = 2*np.random.rand(2)-1\n",
    "        label = 0\n",
    "\n",
    "        # Changing the labels wich is outside of the square\n",
    "        if np.abs(point[0]) > condition[1]:\n",
    "            label = 1\n",
    "\n",
    "        if np.abs(point[1]) > condition[1]:\n",
    "            label = 1\n",
    "\n",
    "        # Collecting the sample points\n",
    "        points.append(point)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(points, requires_grad = False), np.array(labels, requires_grad = False), condition\n",
    "\n",
    "    \n",
    "\n",
    "# ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "def Sphere(samples, condition = [[0,0,0], np.sqrt(2 / np.pi)]):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    samples : the number of data points we will generate\n",
    "    condtion : codition of the sphere (condition[0] = center of the sphere, condtion[1] = radius of the sphere)\n",
    "\n",
    "    OUTPUT\n",
    "    data points & labels(In - 1/Out - -1) for each point & Condition\n",
    "    \"\"\"\n",
    "    points= []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        \n",
    "        # Mading sample points\n",
    "        point = 2*np.random.rand(3)-1\n",
    "        label = 0\n",
    "\n",
    "        # Changing label to 1 if it is out of the circle\n",
    "        if np.linalg.norm(point - condition[0]) > condition[1]:\n",
    "            label = 1\n",
    "        \n",
    "        # Collecting the sample points\n",
    "        points.append(point)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(points, requires_grad = False), np.array(labels, requires_grad = False), condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71777853 -0.25457769]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the data with figuration\n",
    "def plot_data(x, y, fig = None, ax = None, problem = \"\", condition = []):\n",
    "    \"\"\"\n",
    "    Plotting the data with the binary classification\n",
    "\n",
    "    data_points : data_points that will be plotted on the graph\n",
    "    data_labels : which classify the points with different colors\n",
    "\n",
    "    Return\n",
    "    plot graph\n",
    "    \"\"\"\n",
    "    # Graph figure\n",
    "    if fig == None :\n",
    "        fig, ax = plt.subplots(1,1,figsize = (5, 5))\n",
    "    \n",
    "    # Giving color for each point\n",
    "    red = y == 0\n",
    "    blue = y == 1\n",
    "    if problem == None:\n",
    "        print(\"Define the problem\")\n",
    "    \n",
    "    if problem == \"circle\":\n",
    "        draw_circle = plt.Circle(condition[0], condition[1], fill=False)\n",
    "        ax.scatter(x[red,0],x[red,1], c = \"red\", s = 10)\n",
    "        ax.scatter(x[blue,0],x[blue,1], c = \"blue\", s = 10)\n",
    "        ax.add_artist(draw_circle)\n",
    "        ax.set_xlabel(\"$x_1$\")\n",
    "        ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "    if problem == \"sin\":\n",
    "        x1 = np.linspace(-1, 1)\n",
    "        x2 = condition[0]*np.sin(np.pi*x1)\n",
    "        ax.scatter(x[red,0],x[red,1], c = \"red\", s = 10)\n",
    "        ax.scatter(x[blue,0],x[blue,1], c = \"blue\", s = 10)\n",
    "        ax.plot(x1, x2)\n",
    "        ax.set_xlabel(\"$x_1$\")\n",
    "        ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "    if problem == \"square\":\n",
    "        ax.scatter(x[red,0],x[red,1], c = \"red\", s = 10)\n",
    "        ax.scatter(x[blue,0],x[blue,1], c = \"blue\", s = 10)\n",
    "        ax.add_patch(Rectangle((-condition[1],-condition[1]), 2*condition[1], 2*condition[1],\n",
    "                               edgecolor = 'black',lw = 2, fill =False))\n",
    "        ax.set_xlabel(\"$x_1$\")\n",
    "        ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "    if problem == \"sphere\":\n",
    "        theta = np.linspace(0,2*np.pi)\n",
    "        phi = np.linspace(0, 2*np.pi)\n",
    "        theta, phi = np.meshgrid(theta, phi)\n",
    "        r = condition[1]\n",
    "        x1 = condition[0][0] + r*np.cos(theta)*np.sin(phi)\n",
    "        x2 = condition[0][1] + r*np.sin(theta)*np.sin(phi)\n",
    "        x3 = condition[0][2] + r*np.cos(phi)\n",
    "        ax.scatter(x[red,0],x[red,1],x[red,2], c = \"red\")\n",
    "        ax.scatter(x[blue,0],x[blue,1],x[blue,2], c = \"blue\")\n",
    "        ax.plot_surface(x1, x2, x3, cmap=\"viridis\", ec=\"k\", lw=0.05, alpha=0.0)\n",
    "        ax.set_box_aspect((1, 1, 1))\n",
    "        ax.set_xlabel(\"$x_1$\")\n",
    "        ax.set_ylabel(\"$x_2$\")\n",
    "        ax.set_zlabel(\"$x_3$\")\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "Xpoints, Ylabels, condition = Square(500)\n",
    "print(Xpoints[0])\n",
    "plot_data(Xpoints, Ylabels, fig = fig, ax = ax, problem = \"square\" , condition=condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Quantum Circuit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_stochastic = qml.device(\"lightning.qubit\", wires=1, shots=1000)\n",
    "\n",
    "@qml.qnode(dev_stochastic)\n",
    "def SQC_orign(params, x):\n",
    "    \"\"\"\n",
    "    Design the circuit model with the origin scheme\n",
    "\n",
    "    INPUT\n",
    "    params : parameters for the Uitary Gate U(p) (num_layers, 3)\n",
    "    x : one data point (1, 3)\n",
    "    y : label of the data point\n",
    "\n",
    "    OUPUT\n",
    "    expectation vlaue of the circuit\n",
    "    \"\"\"\n",
    "    ### Origin scheme\n",
    "    for p in params:\n",
    "        qml.Rot(*p, wires = 0)\n",
    "        qml.Rot(*x, wires = 0)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_stochastic = qml.device(\"lightning.qubit\", wires=1, shots=1000)\n",
    "\n",
    "@qml.qnode(dev_stochastic)\n",
    "def SQC_comp(thetas, weights, x):\n",
    "    \"\"\"\n",
    "    Variational Quantum Circuit for Universal Quantum Classifier\n",
    "    Fig1.(b) Compressed Scheme\n",
    "\n",
    "    theta : array of theta...bias (theta_1, theta_2, theta_3)\n",
    "    weight : array of wegiht...weight (w_1, w_2, w_3)\n",
    "    x : Datas where we have to input (x_1, x_2, 0)\n",
    "    y : Expected ouput density matrix\n",
    "\n",
    "    Returns\n",
    "    Expectation value\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for i in range(len(thetas)):\n",
    "        params.append(thetas[i]+weights[i]*x)\n",
    "\n",
    "    # Compressed scheme\n",
    "    for p in params:\n",
    "        qml.Rot(*p, wires = 0)\n",
    "    \n",
    "    # Calculating the expectation value of the supplied observable\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_functionO(params, x, y):\n",
    "    \"\"\"\n",
    "    loss function to be minimized\n",
    "\n",
    "    INPUT\n",
    "    params : parmeters that will be used\n",
    "    x : data points for re-uploading\n",
    "    \n",
    "    OUTPUT\n",
    "    loss value to be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        f = SQC_orign(params, x[i])\n",
    "        if y[i] == 0:\n",
    "            loss += (1 - f)**2\n",
    "        else:\n",
    "            loss += (1 + f)**2\n",
    "    return loss / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_functionC(thetas, weights, x, y):\n",
    "    \"\"\"\n",
    "    loss function to be minimized\n",
    "\n",
    "    INPUT\n",
    "    circuit : the circuit model of the classifier\n",
    "    params : parmeters that will be used\n",
    "    x : data points for re-uploading\n",
    "    \n",
    "    OUTPUT\n",
    "    loss value to be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        f = SQC_comp(thetas, weights, x[i])\n",
    "        if y[i] == 0:\n",
    "            loss += (1 - f)**2\n",
    "        else:\n",
    "            loss += (1 + f)**2\n",
    "    return loss / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Runnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_runningO(params, x):\n",
    "    \"\"\"\n",
    "    Model running with given set of data.\n",
    "\n",
    "    INPUT\n",
    "    params : array of parameters (num_layers, 3)\n",
    "    x : array of data points (num_data, 3)\n",
    "    y : array of true data labels (num_data, 1)\n",
    "    state_labels : state representations for labels\n",
    "\n",
    "    Returns\n",
    "    Predicted labels for given data, Expectation value of the circuit\n",
    "    \"\"\"\n",
    "    predicted = []\n",
    "    exepctation_values = []\n",
    "    for i in range(len(x)):\n",
    "        expval = SQC_orign(params, x[i])\n",
    "        exepctation_values.append(expval)\n",
    "        \n",
    "        if expval >= 0 :\n",
    "            predicted.append(0)\n",
    "        else:\n",
    "            predicted.append(1)\n",
    "        \n",
    "    return np.array(predicted), np.array(exepctation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_runningC(thetas, weights, x):\n",
    "    \"\"\"\n",
    "    Model running with given set of data.\n",
    "\n",
    "    INPUT\n",
    "    params : array of parameters (num_layers, 3)\n",
    "    x : array of data points (num_data, 3)\n",
    "    y : array of true data labels (num_data, 1)\n",
    "    state_labels : state representations for labels\n",
    "\n",
    "    Returns\n",
    "    Predicted labels for given data, Expectation value of the circuit\n",
    "    \"\"\"\n",
    "    predicted = []\n",
    "    exepctation_values = []\n",
    "    for i in range(len(x)):\n",
    "        expval = SQC_comp(thetas, weights, x[i])\n",
    "        exepctation_values.append(expval)\n",
    "        \n",
    "        if expval >= 0 :\n",
    "            predicted.append(0)\n",
    "        else:\n",
    "            predicted.append(1)\n",
    "        \n",
    "    return np.array(predicted), np.array(exepctation_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy score. Evaluating the model with the label comparing.\n",
    "    \n",
    "    INPUT\n",
    "    y_true : Targets(Answers)\n",
    "    y_predicted : Predictions(labels wihch model has given)\n",
    "\n",
    "    OUTPUT\n",
    "    the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making batches for optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "    \n",
    "    INPUT\n",
    "    inputs : input data\n",
    "    targets : targets\n",
    "    batch_size : size of the batch, the number of datas in one batch\n",
    "\n",
    "    Returns\n",
    "    one batch of input data of length `batch_size`, one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of Origin scheme SQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m accuracy_train \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, predicted_train)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Running the model with the test data\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m predicted_test, expvals_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_runningO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m accuracy_test \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, predicted_test)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Saving predictions with random weights for comparison \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mmodel_runningO\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m exepctation_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x)):\n\u001b[0;32m---> 17\u001b[0m     expval \u001b[38;5;241m=\u001b[39m \u001b[43mSQC_orign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     exepctation_values\u001b[38;5;241m.\u001b[39mappend(expval)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expval \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m :\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/qnode.py:1039\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[1;32m   1035\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[1;32m   1036\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/interfaces/execution.py:808\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[1;32m    803\u001b[0m ml_boundary_execute \u001b[38;5;241m=\u001b[39m _get_ml_boundary_execute(\n\u001b[1;32m    804\u001b[0m     interface, _grad_on_execution, config\u001b[38;5;241m.\u001b[39muse_device_jacobian_product\n\u001b[1;32m    805\u001b[0m )\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interface \u001b[38;5;129;01min\u001b[39;00m jpc_interfaces:\n\u001b[0;32m--> 808\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mml_boundary_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     results \u001b[38;5;241m=\u001b[39m ml_boundary_execute(\n\u001b[1;32m    811\u001b[0m         tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_diff\u001b[38;5;241m=\u001b[39mmax_diff\n\u001b[1;32m    812\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/interfaces/autograd.py:147\u001b[0m, in \u001b[0;36mautograd_execute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# pylint misidentifies autograd.builtins as a dict\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[1;32m    144\u001b[0m parameters \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mbuiltins\u001b[38;5;241m.\u001b[39mtuple(\n\u001b[1;32m    145\u001b[0m     [autograd\u001b[38;5;241m.\u001b[39mbuiltins\u001b[38;5;241m.\u001b[39mlist(t\u001b[38;5;241m.\u001b[39mget_parameters()) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes]\n\u001b[1;32m    146\u001b[0m )\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/interfaces/autograd.py:168\u001b[0m, in \u001b[0;36m_execute\u001b[0;34m(parameters, tapes, execute_fn, jpc)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@autograd\u001b[39m\u001b[38;5;241m.\u001b[39mextend\u001b[38;5;241m.\u001b[39mprimitive\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\n\u001b[1;32m    152\u001b[0m     parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     jpc,\n\u001b[1;32m    156\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Autodifferentiable wrapper around a way of executing tapes.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/interfaces/execution.py:260\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    258\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(expand_fn(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[0;32m--> 260\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_device_execution(tapes)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/interfaces/execution.py:260\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(expand_fn(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[0;32m--> 260\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_device_execution(tapes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Origin scheme sinle-qubit classifier model\n",
    "\n",
    "# the numbers of training and test data\n",
    "num_training = 500\n",
    "num_test = 4000\n",
    "\n",
    "# Training datas(where we will train the data)\n",
    "Xdata, y_train, condition = Circle(num_training)\n",
    "# for 2-dim points\n",
    "train_data = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Testing datas(where we get the model accuracy)\n",
    "Xtest, y_test, condition = Circle(num_test)\n",
    "# for 2-dim points\n",
    "test_data = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Setting the training options\n",
    "num_layers = 6\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "eta = 0.1\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = GradientDescentOptimizer(eta)\n",
    "\n",
    "# Initializing random weights the parameters for U(p)\n",
    "params = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "### Evaluating the classifier\n",
    "# Running the model with test data\n",
    "predicted_train, expvals_train = model_runningO(params, train_data)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "predicted_test, expvals_test = model_runningO(params, test_data)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_functionO(params, test_data, y_test)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, y_train, batch_size=batch_size):\n",
    "        params, _, _ = opt.step(loss_functionO, params, Xbatch, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_runningO(params, train_data)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = loss_functionO(params, train_data, y_train)\n",
    "\n",
    "    predicted_test, expvals_test = model_runningO(params, test_data)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "\n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cost: {:3f} | Train accuracy {:3f} | Test Accuracy : {:3f}\".format(\n",
    "        loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Learned weights\")\n",
    "for i in range(num_layers):\n",
    "    print(\"Layer {}: prameters = {}\".format(i,params[i]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "plot_data(test_data, initial_predictions, fig, axes[0], problem = \"circle\", condition = condition)\n",
    "plot_data(test_data, predicted_test, fig, axes[1], problem = \"circle\", condition = condition)\n",
    "plot_data(test_data, y_test, fig, axes[2], problem = \"circle\", condition = condition)\n",
    "\n",
    "axes[0].set_title(\"Predictions with random weights\")\n",
    "axes[1].set_title(\"Predictions after training\")\n",
    "axes[2].set_title(\"True test data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[0].plot(loss_list,'.-')\n",
    "axes[1].plot(accuracy_test_list,'.-', label = 'Test_accuracy')\n",
    "axes[1].plot(accuracy_train_list,'.-', label = 'Train_accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(top = 1.0)\n",
    "axes[0].set_title(f\"Loss from fidelity cost function (Layers = {num_layers})\")\n",
    "axes[1].set_title(f\"Accuracy(Layers = {num_layers})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of Compressed scheme SQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numbers of training and test data\n",
    "num_training = 500\n",
    "num_test = 4000\n",
    "\n",
    "# Training datas(where we will train the data)\n",
    "Xdata, y_train, condition = Circle(num_training)\n",
    "train_data = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Testing datas(where we get the model accuracy)\n",
    "Xtest, y_test, condition = Circle(num_test)\n",
    "test_data = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Setting the training options\n",
    "num_layers = 6\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "eta = 0.1\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = GradientDescentOptimizer(eta)\n",
    "\n",
    "# Initializing random weights the parameters for U(p)\n",
    "thetas = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "weights = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "### Evaluating the classifier\n",
    "# Running the model with test data\n",
    "predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_functionC(thetas, weights, test_data, y_test)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, y_train, batch_size=batch_size):\n",
    "        thetas, weights, _, _ = opt.step(loss_functionC, thetas, weights, Xbatch, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = loss_functionC(thetas, weights, train_data, y_train)\n",
    "\n",
    "    predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cost: {:3f} | Train accuracy {:3f} | Test Accuracy : {:3f}\".format(\n",
    "        loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Learned weights\")\n",
    "for i in range(num_layers):\n",
    "    print(\"Layer {}: thetas = {}, weights = {}\".format(i, thetas[i], weights[i]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "plot_data(test_data, initial_predictions, fig, axes[0], problem = \"circle\", condition = condition)\n",
    "plot_data(test_data, predicted_test, fig, axes[1], problem = \"circle\", condition = condition)\n",
    "plot_data(test_data, y_test, fig, axes[2], problem = \"circle\", condition = condition)\n",
    "\n",
    "axes[0].set_title(\"Predictions with random weights\")\n",
    "axes[1].set_title(\"Predictions after training\")\n",
    "axes[2].set_title(\"True test data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[0].plot(loss_list,'.-')\n",
    "axes[1].plot(accuracy_test_list,'.-', label = 'Test accuracy')\n",
    "axes[1].plot(accuracy_train_list,'.-', label = 'Train accuracy')\n",
    "axes[1].set_ylim(top = 1.0)\n",
    "axes[1].legend()\n",
    "axes[0].set_title(f\"Loss from fidelity cost function (Layers = {num_layers})\")\n",
    "axes[1].set_title(f\"Accuracy(Layers = {num_layers})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Origin scheme sinle-qubit classifier model\n",
    "\n",
    "# the numbers of training and test data\n",
    "num_training = 500\n",
    "num_test = 4000\n",
    "\n",
    "# Training datas(where we will train the data)\n",
    "Xdata, y_train, condition = Sin(num_training)\n",
    "# for 2-dim points\n",
    "train_data = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Testing datas(where we get the model accuracy)\n",
    "Xtest, y_test, condition = Sin(num_test)\n",
    "# for 2-dim points\n",
    "test_data = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Setting the training options\n",
    "num_layers = 6\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "eta = 0.1\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = GradientDescentOptimizer(eta)\n",
    "\n",
    "# Initializing random weights the parameters for U(p)\n",
    "thetas = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "weights = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "### Evaluating the classifier\n",
    "# Running the model with test data\n",
    "predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_functionC(thetas, weights, test_data, y_test)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, y_train, batch_size=batch_size):\n",
    "        thetas, weights, _, _ = opt.step(loss_functionC, thetas, weights, Xbatch, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = loss_functionC(thetas, weights, train_data, y_train)\n",
    "\n",
    "    predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cost: {:3f} | Train accuracy {:3f} | Test Accuracy : {:3f}\".format(\n",
    "        loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Learned weights\")\n",
    "for i in range(num_layers):\n",
    "    print(\"Layer {}: thetas = {}, weights = {}\".format(i, thetas[i], weights[i]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "plot_data(test_data, initial_predictions, fig, axes[0], problem = \"sin\", condition = condition)\n",
    "plot_data(test_data, predicted_test, fig, axes[1], problem = \"sin\", condition = condition)\n",
    "plot_data(test_data, y_test, fig, axes[2], problem = \"sin\", condition = condition)\n",
    "\n",
    "axes[0].set_title(\"Predictions with random weights\")\n",
    "axes[1].set_title(\"Predictions after training\")\n",
    "axes[2].set_title(\"True test data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[0].plot(loss_list,'.-')\n",
    "axes[1].plot(accuracy_test_list,'.-', label = 'Test accuracy')\n",
    "axes[1].plot(accuracy_train_list,'.-', label = 'Train accuracy')\n",
    "axes[1].set_ylim(top = 1.0)\n",
    "axes[1].legend()\n",
    "axes[0].set_title(f\"Loss from fidelity cost function (Layers = {num_layers})\")\n",
    "axes[1].set_title(f\"Accuracy(Layers = {num_layers})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 1.044690 | Train accuracy: 0.628000 | Test Accuracy: 0.648800\n",
      "Epoch:  1 | Loss: 0.869678 | Train accuracy: 0.689000 | Test accuracy: 0.713600\n",
      "Epoch:  2 | Loss: 0.759178 | Train accuracy: 0.729000 | Test accuracy: 0.760800\n",
      "Epoch:  3 | Loss: 0.667143 | Train accuracy: 0.781000 | Test accuracy: 0.800000\n",
      "Epoch:  4 | Loss: 0.595682 | Train accuracy: 0.801000 | Test accuracy: 0.817600\n",
      "Epoch:  5 | Loss: 0.531196 | Train accuracy: 0.820000 | Test accuracy: 0.828400\n",
      "Epoch:  6 | Loss: 0.493614 | Train accuracy: 0.842000 | Test accuracy: 0.852200\n",
      "Epoch:  7 | Loss: 0.473917 | Train accuracy: 0.855000 | Test accuracy: 0.865600\n",
      "Epoch:  8 | Loss: 0.461708 | Train accuracy: 0.856000 | Test accuracy: 0.867200\n",
      "Epoch:  9 | Loss: 0.453510 | Train accuracy: 0.867000 | Test accuracy: 0.867600\n",
      "Epoch: 10 | Loss: 0.448404 | Train accuracy: 0.865000 | Test accuracy: 0.868400\n",
      "Epoch: 11 | Loss: 0.441856 | Train accuracy: 0.867000 | Test accuracy: 0.869200\n",
      "Epoch: 12 | Loss: 0.437324 | Train accuracy: 0.872000 | Test accuracy: 0.870400\n",
      "Epoch: 13 | Loss: 0.434507 | Train accuracy: 0.872000 | Test accuracy: 0.874200\n",
      "Epoch: 14 | Loss: 0.435235 | Train accuracy: 0.879000 | Test accuracy: 0.873800\n",
      "Epoch: 15 | Loss: 0.430362 | Train accuracy: 0.881000 | Test accuracy: 0.874600\n"
     ]
    }
   ],
   "source": [
    "### Origin scheme sinle-qubit classifier model\n",
    "\n",
    "# the numbers of training and test data\n",
    "num_training = 1000\n",
    "num_test = 5000\n",
    "\n",
    "# Training datas(where we will train the data)\n",
    "Xdata, y_train, condition = Square(num_training)\n",
    "# for 2-dim points\n",
    "train_data = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Testing datas(where we get the model accuracy)\n",
    "Xtest, y_test, condition = Square(num_test)\n",
    "# for 2-dim points\n",
    "test_data = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False))) # point (x_1, x_2, x_3 = 0)\n",
    "\n",
    "# Setting the training options\n",
    "num_layers = 12\n",
    "epochs = 50\n",
    "batch_size = 250\n",
    "eta = 0.07\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = GradientDescentOptimizer(eta)\n",
    "\n",
    "# Initializing random weights the parameters for U(p)\n",
    "thetas = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "weights = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "### Evaluating the classifier\n",
    "# Running the model with test data\n",
    "predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_functionC(thetas, weights, test_data, y_test)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, y_train, batch_size=batch_size):\n",
    "        thetas, weights, _, _ = opt.step(loss_functionC, thetas, weights, Xbatch, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = loss_functionC(thetas, weights, train_data, y_train)\n",
    "\n",
    "    predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cost: {:3f} | Train accuracy {:3f} | Test Accuracy : {:3f}\".format(\n",
    "        loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Learned weights\")\n",
    "for i in range(num_layers):\n",
    "    print(\"Layer {}: thetas = {}, weights = {}\".format(i, thetas[i], weights[i]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "plot_data(test_data, initial_predictions, fig, axes[0], problem = \"square\", condition = condition)\n",
    "plot_data(test_data, predicted_test, fig, axes[1], problem = \"square\", condition = condition)\n",
    "plot_data(test_data, y_test, fig, axes[2], problem = \"square\", condition = condition)\n",
    "\n",
    "axes[0].set_title(\"Predictions with random weights\")\n",
    "axes[1].set_title(\"Predictions after training\")\n",
    "axes[2].set_title(\"True test data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[0].plot(loss_list,'.-')\n",
    "axes[1].plot(accuracy_test_list,'.-', label = 'Test accuracy')\n",
    "axes[1].plot(accuracy_train_list,'.-', label = 'Train accuracy')\n",
    "axes[1].set_ylim(top = 1.0)\n",
    "axes[1].legend()\n",
    "axes[0].set_title(f\"Loss from fidelity cost function (Layers = {num_layers})\")\n",
    "axes[1].set_title(f\"Accuracy(Layers = {num_layers})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Origin scheme sinle-qubit classifier model\n",
    "\n",
    "# the numbers of training and test data\n",
    "num_training = 750\n",
    "num_test = 2000\n",
    "\n",
    "# Training datas(where we will train the data)\n",
    "train_data, y_train, condition = Sphere(num_training)\n",
    "\n",
    "# Testing datas(where we get the model accuracy)\n",
    "test_data, y_test, condition = Sphere(num_test)\n",
    "\n",
    "# Setting the training options\n",
    "num_layers = 10\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "eta = 0.1\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = GradientDescentOptimizer(eta)\n",
    "\n",
    "# Initializing random weights the parameters for U(p)\n",
    "thetas = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "weights = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "### Evaluating the classifier\n",
    "# Running the model with test data\n",
    "predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_functionC(thetas, weights, test_data, y_test)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, y_train, batch_size=batch_size):\n",
    "        thetas, weights, _, _ = opt.step(loss_functionC, thetas, weights, Xbatch, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_runningC(thetas, weights, train_data)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = loss_functionC(thetas, weights, train_data, y_train)\n",
    "\n",
    "    predicted_test, expvals_test = model_runningC(thetas, weights, test_data)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cost: {:3f} | Train accuracy {:3f} | Test Accuracy : {:3f}\".format(\n",
    "        loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Learned weights\")\n",
    "for i in range(num_layers):\n",
    "    print(\"Layer {}: thetas = {}, weights = {}\".format(i, thetas[i], weights[i]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 6),subplot_kw={\"projection\":\"3d\"})\n",
    "plot_data(test_data, initial_predictions, fig, axes[0], problem = \"sphere\", condition = condition)\n",
    "plot_data(test_data, predicted_test, fig, axes[1], problem = \"sphere\", condition = condition)\n",
    "plot_data(test_data, y_test, fig, axes[2], problem = \"sphere\", condition = condition)\n",
    "\n",
    "axes[0].set_title(\"Predictions with random weights\")\n",
    "axes[1].set_title(\"Predictions after training\")\n",
    "axes[2].set_title(\"True test data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[0].plot(loss_list,'.-')\n",
    "axes[1].plot(accuracy_test_list,'.-', label = 'Test accuracy')\n",
    "axes[1].plot(accuracy_train_list,'.-', label = 'Train accuracy')\n",
    "axes[1].set_ylim(top = 1.0)\n",
    "axes[1].legend()\n",
    "axes[0].set_title(f\"Loss from fidelity cost function (Layers = {num_layers})\")\n",
    "axes[1].set_title(f\"Accuracy(Layers = {num_layers})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
