{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[arXiv:1907.02085v3]](https://arxiv.org/abs/1907.02085)Data re-uploading for a universal quantum classifier\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data re-uploading is considered as a manner of solving the limitations established by $ \\textit{no-cloning teorem} $\n",
    "> **DATA USING**\n",
    "<br>    NN : taking the same input many times when processing the data in the hidden layer neurons\n",
    "<br>    QNN : only using quantum data once.\n",
    "\n",
    "Re-uploading classical data along a quantum computation to bypass this limitation on the quantum circuit\n",
    "\n",
    "**Section 2**\n",
    " - Basic sturcture of a single-qubit quantum classifier\n",
    " - Data and processing parameters are uploaded and re-uploaded using one-qubit general rotation\n",
    " - Final state is compared with the target state\n",
    " - Parameters are updated by using classical minimiztion algorithm\n",
    "\n",
    "**Section 3**\n",
    " - Data re-uploading approach by using 'Univesal Approximation Theorem' of ANN\n",
    "\n",
    "**Section 4**\n",
    " - Extension of the classifier to multiple qubits\n",
    "\n",
    "**Section 5**\n",
    " - Minimization method used to train the quantum classifier\n",
    "\n",
    "**Section 6, 7**\n",
    " - Results and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Structure of a single-qubit quantum classifier\n",
    "\n",
    "Quantum Circuit(QC) $\\Leftarrow $ (*uploading of information onto a quantum state*) + (*processing of the quantum state*) + (*measurement of the final state*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Re-uploading classical information\n",
    "\n",
    "It is not obvious to upload large amounts of data onto a state\n",
    "<br>__Possible to consider a quantum circuit where all data are loaded in the coefficients of the initial wave function__\n",
    "<br>Data - > Rotations of qubits in computational basis\n",
    "\n",
    "> **Limitation**<br>\n",
    "> Insufficient...for a single-qubit classifier<br>\n",
    ">> 1. Only two degrees of freedom.\n",
    ">> 2. Once the data is uploaded, the only quantum circuit available is a rotation in Bloch sphere.\n",
    "\n",
    "Single rotation cannot capture any non-trivial seperation of patterns\n",
    "\n",
    "[NN]Feed-froward neural network ; data are entered in a network in such a way that they are processed by subsequent layers of neurons<br>\n",
    "[QNN]Building a universal quatum classifier with a single-qubit ; Re-uploading classical data\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src = \"Figures/[1907.02085]Figure1.png\" width = 30% title=\"Figure 1\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Processing along re-uploading\n",
    "\n",
    "The processing gates present int the circuit in terms of a classical set of parameters\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src = \"Figures/[1907.02085]Figure2.png\" width = 30% title=\"Figure 2\" >\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"left\">\n",
    "The data is introduced in a simple rotation of the qubit\n",
    "\n",
    "Using arbitrary single-qubit rotation $U(\\phi_1, \\phi_2, \\phi_3)\\in SU(2)$ writting $\\vec{\\phi} = (\\phi_1, \\phi_2, \\phi_3)$\n",
    ">**Universal Gate**<br>\n",
    ">$\\mathcal{U}(\\vec{\\phi},\\vec{x}) \\equiv U(\\vec{\\phi}_N)U(\\vec{x}) \\dots U(\\vec{\\phi}_1)U(\\vec{x})$<br>\n",
    ">$\\Rightarrow$ $\\ket{\\psi} = \\mathcal{U}(\\vec{\\phi},\\vec{x})\\ket{0}$\n",
    "\n",
    "The final calssification of pattrens will come from the results of measurements on $\\ket{\\psi}$\n",
    "\n",
    ">**Processing Layer**<br>\n",
    "> $L(i) \\equiv U(\\vec{\\phi}_i)U(\\vec{x})  \\Longrightarrow \\mathcal{U}(\\vec{\\phi},\\vec{x}) = L(N)\\dots L(1) $<br>\n",
    "> Circuit depth = $2N$\n",
    "\n",
    ">**Compactifying the layer**<br>\n",
    "> *Incoporate data and processing anles in a single step*<br>\n",
    "> $ \\Rightarrow$ $ L(i) = U(\\vec{\\theta}_i + \\vec{\\omega}_i \\circ \\vec{x}) $ where $\\vec{\\omega}_i \\circ \\vec{x} = ({\\omega_i^1}{x^1},{\\omega_i^2}{x^2},{\\omega_i^3}{x^3}) $<br>\n",
    "> In this case the data points have dimension lesser than three, the rest of $\\vec{x}$ components are $0$<br>\n",
    "> Circuit depth = $N$\n",
    "\n",
    "Non-linearities comes from the structure of these base gates.<br>\n",
    "Since of the structure of the gate, the encoding is particularly suited for data with *rotatational symmetry*\n",
    "\n",
    "For further techniques,<br>\n",
    "We can enlarge the dimensionality of the input space in the following way. <br>\n",
    "$$L(i) = U({\\vec{\\theta}_i^{(k)}}+{\\vec{\\omega}_i^{(k)}} \\circ {\\vec{x}_i^{(k)}}) \\cdots U({\\vec{\\theta}_i^{(1)}}+{\\vec{\\omega}_i^{(1)}} \\circ {\\vec{x}_i^{(1)}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Measurement\n",
    "\n",
    "Quantum circuit characterized by a series of processing angles {$\\theta_i$} and weights {$\\omega_i$}<br>\n",
    "Making the final state $\\ket{\\psi}$, which needs to be measured\n",
    "\n",
    "Computing $\\chi^2$ that quantifies the error made in classification $\\rightarrow$ Minimization of $\\chi^2$\n",
    "\n",
    "**Critical poin in the quantum measurement = (Finding an optimal way to associate outputs from the observation to targets)**\n",
    "<br><br><br>\n",
    "For single-qubit\n",
    "\n",
    "The idea of maximal orthogonality of outputs (C. W. Helstrom, *'[Quantum detection and estimation theory](https://link.springer.com/article/10.1007/BF01007479)'*)<br>\n",
    "$ \\rightarrow $ **Dichotomic Classification**(2 classes problem)\n",
    "> Output possibility ($P(0) for \\ket{0}, P(1) for \\ket{1}$)\n",
    ">> $P(0)>P(1)$ : class A, $P(0)<P(1)$ : class B<br>\n",
    ">> Or<br>\n",
    ">> $P(0)>\\lambda$ : class A, $P(0)<\\lambda$ : class B\n",
    "\n",
    "For many classes,<br>\n",
    "- Comparing the probability $P(0)$ : for four sectors $ 0 \\leq \\lambda_1 \\leq \\lambda_2 \\leq \\lambda_3 \\leq 1 $\n",
    "- Computing the overlap of the final state to one of the states of a label states-set<br>\n",
    "> This states-set is chosen with *maximal orthogonality* among all of them<br>\n",
    "> Needs from maximally orthogonal points in the Bloch sphere<br>\n",
    "> Example for four and six classes<br>\n",
    "><div align=\"center\"><img src = \"Figures/[1907.02085]Figure3.png\" width = 30% title=\"Figure 3\" ><br>\n",
    "><div align=\"left\">Good measurement tragedy may need some prior computational effort and refined tomography of the final state\n",
    "\n",
    "***Single-qubit classifier $\\rightarrow$ goemetry of the Bloch sphere**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1. A fidelity cost function\n",
    "\n",
    "Want to force the quantum states $\\ket{\\psi(\\vec{\\theta},\\vec{\\omega},\\vec{x})}$ to be as near as possible to one particular state on Bloch sphere<br>\n",
    "$\\mapsto$ Angular distance between two states (M. A. Nielson and I. L. Chuang, *['Quantum Computation and Quantum Information'](https://www.amazon.com/Quantum-Computation-Information-10th-Anniversary/dp/1107002176)*)<br>\n",
    "**Aim** : maximize the average fidelity between the states at the end of the circuit and the label states corresponding to their class\n",
    "\n",
    "***Cost Function***<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "$ \\chi_f^2(\\vec{\\theta}, \\vec{\\omega}) = \\sum_{\\mu = 1}^M (1 - |\\langle\\tilde{\\psi}_s | \\psi(\\vec{\\theta}, \\vec{\\omega}, \\vec{x}_{\\mu})\\rangle|^2)$ where $\\ket{\\tilde{\\psi}_s}$ is the correct label state of the $\\mu$ data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 Weighted fidelity cost function\n",
    "\n",
    "*Refined Version*<br><br>\n",
    "$\\ket{\\psi}_c$ : label state where $c$ is the class<br>\n",
    "$F_c(\\vec{\\theta}, \\vec{\\omega}, \\vec{x}) = |\\langle \\tilde{\\psi_c} | \\psi(\\vec{\\theta}, \\vec{\\omega}, \\vec{x})\\rangle|^2 $<br>\n",
    "$ M $ : the total number of training point<br>\n",
    "$ Y_c(\\vec{x}) $ : Expected fidelity of a successful classification\n",
    "\n",
    "> [Example] Four classes problem with fig3<br>\n",
    "> $ Y_s(\\vec{x}) = 1 $, where $s$ is the correct class, and $ Y_r(\\vec{x}) = {1 \\over 3} $ for the other $r$ classes<br>\n",
    "> $ Y_c(\\vec{x}) $ can be written as a verctor with the correct class, and the others containing the overlap between the correct class label and the other label states<br>\n",
    "> $Y_c(\\vec{x}) = (s = 1, r_1 = {1 \\over 3},r_2 = {1 \\over 3},r_3 = {1 \\over 3})$ where the correct class is $s$  <br>\n",
    "\n",
    "***Weighted fidelity cost function***\n",
    "$$ \n",
    "\\chi_{\\omega f}^2(\\vec{\\alpha},\\vec{\\theta}, \\vec{\\omega}) \n",
    "= \n",
    "{1 \\over 2} \\sum_{\\mu = 1}^M\n",
    "\\left(\n",
    "    \\sum_{c=1}^C \n",
    "    \\left(\n",
    "        \\alpha_c F_c(\\vec{\\theta}, \\vec{\\omega}, \\vec{x_\\mu}) - Y_c(\\vec{x}_\\mu)\n",
    "    \\right)\n",
    "\\right) \n",
    "$$\n",
    "\n",
    "Difference between *fidelity cost function* and *weighted fidelity function* \n",
    "- How many overlaps do we need to compute\n",
    "    - *weighted fidelity cost function* requires as many fidelities as classes every time we run the optimization subroutine\n",
    "    - *fidelity cost function* needs just one\n",
    "- Forcing the state...\n",
    "    - *fidelity cost function* forces the parameters to reach the maximum in the fidelities; moves the qubit state to where it should be\n",
    "    - *weighted fidelity cost function* forces the parameters to be close to a specified configuration of fidelities;<br>moves the qubit state to where it should be and moves away from where it should not be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3. Universality of the single-qubit classifier\n",
    "\n",
    "Universal Approximation Theorem of aritificial neural network(Kurt Hornik, *['Approximation capabilities of multilayer feedforward networks](https://www.sciencedirect.com/science/article/abs/pii/089360809190009T)'*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Universal Approximation Theorem\n",
    "\n",
    ">*Theorem*<br>\n",
    ">Let $I_m = [0, 1]^m$ be the $m$-dimensional unit cube and $C(I_m)$ the space of continuous functions in $I_m$.<br>\n",
    ">Let the function $\\phi : \\mathbb{R}  \\rightarrow \\mathbb{R}$ be a nonconstant, bounded and continuous function and $ f : I_m \\rightarrow \\mathbb{R} $ a function.<br>\n",
    ">Then, for every $\\epsilon > 0 $ there exists an integer $ N $ and a fucntion $ h : I_m \\rightarrow \\mathbb{R} $, defined as\n",
    ">$$ h(\\vec{x}) = \\sum_{i=1}^N \\alpha_i \\phi(\\vec{\\omega}_i\\cdot \\vec{x}+b_i) $$\n",
    ">with $ \\alpha_i, b_i \\in \\mathbb{R}$ and $\\vec{\\omega}_i \\in \\mathbb{R}^m $, s.t. $h$ is an approximate realization of $f$ withe precision $\\epsilon$,i.e.,\n",
    ">$$|h(\\vec{x})-f(\\vec{x})| < \\epsilon $$\n",
    "\n",
    "In ANN,<br>\n",
    "- $\\phi$ : the activation function<br>\n",
    "- $\\vec{\\omega}_i$ :  the weights for each neurons<br>\n",
    "- $b_i$ : biases<br>\n",
    "- $\\alpha_i$ : the neuron wiehgts that construct the output function<br>\n",
    "\n",
    "***It is possible to reconstruct any continous function with a single layer neural network of $N$ neurons***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Universal Quantum Circuit Approximation\n",
    "\n",
    "Decompostion of $SU(2)$ rotational matrix<br>\n",
    "(PAPER)<br> \n",
    "$$\n",
    "U(\\vec{\\phi}) = U(\\phi_1, \\phi_2, \\phi_3) = e^{i\\phi_2\\sigma_z}e^{i\\phi_1\\sigma_y}e^{i\\phi_3\\sigma_z}\n",
    "\\underset{SU(2) \\text{group composition law}}{\\Rightarrow} \n",
    "U(\\vec{\\phi})=e^{i \\vec{\\omega}(\\vec{\\phi})\\cdot \\vec{\\sigma}} \\\n",
    " \\text{with} \\ \n",
    "\\vec{\\omega}(\\vec{\\phi}) = \\left( \\omega_1(\\vec{\\phi}), \\omega_2(\\vec{\\phi}), \\omega_3(\\vec{\\phi}) \\right) \n",
    "$$<br>\n",
    "and<br>\n",
    "- $ \\omega_1(\\vec{\\phi}) = d \\mathcal{N} \\sin{((\\phi_2-\\phi_3) / 2)}\\sin{\\phi_1/2} $\n",
    "- $ \\omega_2(\\vec{\\phi}) = d \\mathcal{N} \\cos{((\\phi_2-\\phi_3) / 2)}\\sin{\\phi_1/2} $\n",
    "- $ \\omega_3(\\vec{\\phi}) = d \\mathcal{N} \\sin{((\\phi_2+\\phi_1) / 2)}\\cos{\\phi_1/2} $\n",
    "\n",
    "where $\\mathcal{N} = (\\sqrt{1-\\cos^2{d}})^{-1}$ and $\\cos{d} = \\cos{((\\phi_2+\\phi_3)/2)\\cos{(\\phi_1/2)}}$\n",
    "\n",
    "Single-qubit classifier codifies the data points into $\\vec{\\phi}$ parameters of the $U$ unitary gate<br>\n",
    "> Re-upload data together with the tunable parameters<br>\n",
    "> $\\vec{\\phi}(\\vec{x}) = (\\phi_1(\\vec{x}), \\phi_2(\\vec{x}), \\phi_3(\\vec{x})) = \\vec{\\theta} + \\vec{\\omega} \\circ \\vec{x}$<br><br>\n",
    "> $\\mathcal{U}(\\vec{x}) = U_N(\\vec{x})U_{N-1}(\\vec{x}) \\dots U_1(\\vec{x}) = \\prod_{j=1}^N e^{i \\vec{\\omega}(\\vec{\\phi_j}(\\vec{x}))\\cdot \\vec{\\sigma}} $<br><br>\n",
    "> Baker-Campbell-Hausdorff(BCH) formula<br>\n",
    "> $\\mathcal{U}(\\vec{x}) = exp \\left[ i \\sum_{i=1}^N \\vec{\\omega}(\\vec{\\phi}(\\vec{x}))\\cdot\\vec{x} + \\mathcal{O}_{corr}\\right]$ where $\\mathcal{O}_{corr}$ are also proportional to Pauli matrices due to $[\\sigma_i, \\sigma_j] = 2i\\epsilon_{ijk}\\sigma_k$\n",
    "\n",
    "<br>\n",
    "\n",
    "Each $\\vec{\\omega}$ terms are trigometric functions(unconstant, bounded and continuous)<br>\n",
    "$\\sum_{i=1}^N \\vec{\\omega}(\\vec{\\phi}_i(\\vec{x}))$ <br>\n",
    "$= \\sum_{i=1}^N \\left( \\omega_1(\\vec{\\phi}_i(\\vec{x})), \\omega_2(\\vec{\\phi}_i(\\vec{x})), \\omega_3(\\vec{\\phi}_i(\\vec{x})) \\right)$ <br>\n",
    "$= \\sum_{i=1}^N \\left( \\omega_1(\\vec{\\theta}_i + \\vec{\\omega}_i\\circ\\vec{x}), \\omega_2(\\vec{\\theta}_i + \\vec{\\omega}_i\\circ\\vec{x}), \\omega_3(\\vec{\\theta}_i + \\vec{\\omega}_i\\circ\\vec{x}) \\right)$<br>\n",
    "$= (f_1(\\vec{x}),f_2(\\vec{x}),f_3(\\vec{x}))$<br><br>\n",
    "\n",
    "The remaining terms $\\mathcal{O}_{corr}$ of BCH expansion($SU(2)$ group composition law)<br>\n",
    "$>>>$ $\\mathcal{U}(\\vec{x}) = e^{i\\xi(\\vec{x})\\cdot\\vec{\\sigma}}$ where $\\xi(\\vec{x})$ will be an inextricably trigometric function of $\\vec{x}$\n",
    "$$ \\mathcal{U}(\\vec{x}) = e^{i\\xi(\\vec{x})\\cdot\\vec{\\sigma}} = e^{i\\vec{f}(\\vec{x})\\cdot\\vec{\\sigma}+i\\vec{\\rho}(\\vec{x})\\cdot\\vec{\\sigma}}$$\n",
    "\n",
    "With *weighted fidelity cost function*\n",
    "The function obtained from the combination $\\xi(\\vec{x})$ and $\\alpha_c$ is expected to be complex enough to probably represent almost any continuous function<br>\n",
    "However, more parameters are necessary to map this argument with the UAT expression\n",
    "\n",
    "Comparing the parameters\n",
    "- $\\vec{\\omega}_i$ : the weights\n",
    "- $\\vec{\\theta}_i$ : the biases $b_i$\n",
    "- the number of layers $N$ : the number of neurons in the hidden layer\n",
    "- $\\vec{\\omega}$ : the activation fucntion $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4. Single- to multi-qubit quantum classifier\n",
    "\n",
    "(???) Single-qubit classifier cannot carry any quantum advantage respect classical classification techniques s.t. ANN<br>\n",
    "\n",
    "A huge amount of hidden neurons is necessary to approximate a target function with a single layer<br>\n",
    "$\\cdot$ More hidden layers $\\rightarrow$ *deep neural network*\n",
    "\n",
    "Generalization to multi-qubits<br>\n",
    "Multiple qubits to quantum classifier may imporve its performance as more hidden layrers improve the classification task of an ANN work<br>\n",
    "Entaglment $\\longrightarrow$ reduce the number of layers of classifier as well as propose a qunatum classification method that can achieve quantum advantage\n",
    "\n",
    "*The generalization of this analogy is not obvious*<br>\n",
    "Multi qubit classifier $\\sim$ CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Measurement strategy and cost function for a multi-qubit classifier\n",
    "\n",
    "If more qubirs are to be considered, tomography protocols become exponentially expensive in terms of number of measurement\n",
    "\n",
    "\n",
    "**Measurement Strategy**\n",
    "1. The natural generalization of the single-qubit strategy(Unrealizable for a large number of qubits)<br>\n",
    "    $\\rightarrow$ Comparing the final state with one of the states of the computational basis<br>\n",
    "    Cost function = fidelity cost function<br>\n",
    "\n",
    "2. Focusing in one qubit and depending on its state associate one or other class<br>\n",
    "    $\\sim$ Propsals of binary multi-qubit classifier<br>\n",
    "    $+$ The possibility of multiclass classification<br>\n",
    "    Cost function = weighted fidelity function...\n",
    "    > ***Focusing on one qubit***<br>\n",
    "    > $$F_{c,q}(\\vec{\\theta}, \\vec{\\omega}, \\vec{x}) = \\langle \\tilde{\\psi}_c|\\rho_q(\\vec{\\theta}, \\vec{\\omega}, \\vec{x})|\\tilde{\\psi}_c\\rangle$$\n",
    "    > where $\\rho_q$ is the reduced density matrix of the qubit to measured<br>\n",
    "    > $$ \\chi_{\\omega f}^2(\\vec{\\alpha},\\vec{\\theta}, \\vec{\\omega}) \n",
    "= \n",
    "{1 \\over 2} \\sum_{\\mu = 1}^M\\sum_{c=1}^C\n",
    "\\left(\n",
    "    \\sum_{q=1}^Q \n",
    "    \\left(\n",
    "        \\alpha_{c,q} F_{c,q}(\\vec{\\theta}, \\vec{\\omega}, \\vec{x_\\mu}) - Y_c(\\vec{x}_\\mu)\n",
    "    \\right)\n",
    "\\right) \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Quantum Circuit Example\n",
    "\n",
    "For a multi-qubit quantum classifier, there is extra degree of freedom in the circuit-design<br>\n",
    "Problem : There is no obvisous correct ansatz for the entangling structure of the circuit<br>\n",
    "\n",
    "***Example***\n",
    "<div align=\"center\">\n",
    "<img src = \"Figures/[1907.02085]Figure4.png\" width = 30% title=\"Figure 4\" >\n",
    "<div align=\"center\">\n",
    "<img src = \"Figures/[1907.02085]Figure5.png\" width = 30% title=\"Figure 5\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Minimization Method\n",
    "\n",
    "To be precise, the set of $\\{\\theta_i\\}$ angles, $\\{\\omega_i\\}$ weghts, and together with $\\alpha_{q,l}$ parmaeters, forms a space to be explored in search of a minimum $\\chi^2$<br>\n",
    "Minimizing a function of many parameters<br>\n",
    "\n",
    "- Single-qubit classifier\n",
    "    - the number of parameters = $(3+d)N $ (d:dimension of the problem i.e. the dimenstionn of $\\vec{x}$, $N$: the layers)\n",
    "\n",
    "The minimizer is taken as a black box whose parameters are set by default\n",
    "\n",
    "**Stochasitc Gradient Descent(SGD)** & **L-BFGS-B**\n",
    "\n",
    "|   |SGD|L-BFGS_B|\n",
    "|---|:---:|:---:|\n",
    "|fidelity cost function|   | O |\n",
    "|small training data|   | O |\n",
    "|large trainging data| O |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "-----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
